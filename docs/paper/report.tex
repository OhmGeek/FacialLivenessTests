\documentclass[10pt,a4paper]{article}
\usepackage{times}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{durhampaper}
\usepackage{subfigure}
\usepackage{todonotes}
% \usepackage{harvard}
% \usepackage[moderate]{savetrees}
\usepackage{url}

\title{Facial Liveness Testing: For The Web}
\author{} % leave; your name goes into \student{}
\student{Ryan Collins}
\supervisor{Prof A. Krokhin}
\degree{MEng Computer Science}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
% These instructions give you guidelines for preparing the final paper.  DO NOT change any settings, such as margins and font sizes.  Just use this as a template and modify the contents into your final paper.  Do not cite references in the abstract.

% The abstract must be a Structured Abstract with the headings {\bf Context/Background}, {\bf Aims}, {\bf Method}, {\bf Results}, and {\bf Conclusions}.  This section should not be longer than half of a page, and having no more than one or two sentences under each heading is advised.
\paragraph{Context/Background}
    \todo{TODO context}

\paragraph{Aims}
    \todo{TODO}

\paragraph{Method}
    \todo{TODO}

\paragraph{Results}
    \todo{TODO}
\paragraph{Conclusions}
    \todo{TODO}

\end{abstract}

\begin{keywords}
Facial liveness, convolutional neural networks, image quality metrics
\end{keywords}

\section{Introduction}
    % What is the project about?
    Currently, username and password authentication is commonplace throughout the web. However, username and password
    based authentication systems have a number of problems. Some common passwords can be broken using dictionary attacks,
    especially if they consist partially or entirely of a word in a standard dictionary. Furthermore, the process of shoulder surfing is possible (watching out
    for someone's password, and how they type it).

    An easy to use system is necessary to remove the choice from the user (in terms of password), relying on the user being automatically
    detected, and several confirmation methods to ensure the user is indeed who they say they are (and not just someone spoofing the system).
    Before such a system is developed, a facial liveness testing method must be found that operated in near real-time, and that is fairly accurate.


\section{Related Work}
    % LIT REVIEW GOES HERE!
    % - First basic metrics
    % - image Quality assessment (different types of image quality metrics used ,and why they should be effective). Drawbacks of these
    % - movement based assessment (requiring actions to be performed, and their problems).
    % - Deep Learning methods (what methods exist, their performance)
    % - 3D mask prevention methods (kinect based ones that require 3D input, or SFM, which isn't really valid here)
\section{Solution}
    % Solution to the problem
    \subsection{Image Quality Assessment based liveness test}
        For 2D spoofing attacks, spoofed images are typically lower quality than the real images, and thus by measuring the image quality
        one can train a classifier to detect real and spoofed images respectively.

        The method used, based on the work of \citet{ImageQualityAssessmentTest}, implements 24 different metrics with varying differences, and produces
        a vector for each image. Initially, classification was done using a Support Vector Machine (SVM), but after experimentation this proved to be fairly
        unreliable (yielding 70\% accuracy on the test set). The classifier was later changed to use Linear Discriminant Analysis (LDA) which yielded a much improved
        accuracy (96\% accuracy on the test set). \todo[inline]{TODO: give more accuracy figures of accuracy here, I can't remember the exact numbers}.

    \subsection{Residual Network based 2D liveness test}
        Recently, 2D convolutional neural networks have had great success in image classification tasks. Therefore, it might be possible to train
        a residual neural network (resnet) to classify for facial liveness tasks.

        In order to simplify the process of training, an existing resnet model (ResNet50) was used, with only the final convolutional layer being
        set to trainable. This is because the initial convolutional layers contain the standard features contained within images, while the final one
        learns bundles of features. Internal feed forward activations use relu, while the external output uses the softmax activation function

        Training was completed using the categorical cross-entropy loss function (as this is considered multiclass).
        We yield a 2-tuple output from this model, which is the probability of each possible case. We take the value with the highest probability as the true outcome.

        The output of this ResNet model is then fed into a 2D Max Pooling layer, which then feeds into a feed forward neural network.
        Initially, the model was trained using the Adam optimiser, but this yielded poor accuracy (75\% accuracy). Utilising the standard
        gradient descent (SGD) optimiser with a low learning rate yielded far greater accuracy.

        \missingfigure{TODO: insert diagram of architecture of our final resnet model}
        \todo{TODO: insert citation for trying pretrained imagenet}

    \subsection{A system for preventing 3D spoofing attacks}
        While the systems before might go partially towards preventing 3D spoofing attacks, though primarily considering the 2D image, we now propose a method
        that is designed for classifying facial liveness based on a 3D point cloud.

        \subsubsection{Point Cloud Reconstruction}
            In order to classify an image/video, a 3D point cloud needs to be created, containing many 3D points $(x,y,z)$
            of a user's face. While 3d reconstruction is easier with videos (using structure from motion or other multiview based methods),
            there also exist image-based reconstruction methods such as vrn (\citealt{3DReconstructionMethod}) which are more specific and designed for reconstructing faces based on images.

        \subsubsection{3D point cloud classification}
            Once the 3D reconstruction is obtained, one can then classify this using some model to produce the fake/real metric.

            For points, PointNet is a model that can be used \todo[inline]{EXPLAIN POINTNET}

            However, as we are using voxels, there is a more specialised architecutre called Voxnet that is designed for classifying
            3d volume-based objects. VoxNet takes in a point cloud and converts this to an occupancy grid. This is then fed through two convolutional layers,
            pooled, and then goes through a dense layer before reaching the classifier output (a dense layer with the k outcomes). 

            Instead of training on our existing datasets, we first train a VoxNet model on the SUOD dataset, in order to learn the basic features surrounding
            3D classification. This largely uses the tools provided in the original implementation of VoxNet, but with a custom Keras implementation. This pretrained
            model is then saved, for use in our final implementation.

            Using this original VoxNet implementation, the last dense layer is then ignored, with it being extended to contain further dense layers, and an eventual output classifier (for fake/real respectively).
           
        \subsubsection{How this overall system functions}
            Each image is first preprocessed: the image is fed through the 3D reconstruction network, and the output is a set of Voxels.
            Using these voxels, they are then resized into a (24 x 24 x 24) shape to provide a basis for the network. From here, they are
            fed through several convolutional layers, before then being fed through several dense layers for classification. 

            \missingfigure{INSERT FIGURE HERE CONTAINING PIPELINE}
    \subsection{Visualisation and Demonstration}
        In order to visualise the overall outcome of facial liveness, a generic model 
\section{Results}
    % based on the solution, what results did we yield? What did we find out?
    \textbf{TODO results}
\section{Evaluation}
    % How well our system works, how well did it assess stuff, and how it can be improved.
    % what are the uses of our research? e.g. influence and improve the design of xyz...
    \textbf{TODO evaluation}


    % Improvements:
    % 3D attacks more difficult. One could extend this method using 3D reconstruction (sfm based on videos)
    % then recovering 3D details, and using these as input features.
    % this would allow for 3D reconstruction to some extent. Would require video input.
\section{Conclusions}
    % overall, what did the project show?


\bibliographystyle{plain}
\bibliography{report}

\end{document}