\documentclass[final]{beamer}
% beamer 3.10: do NOT use option hyperref={pdfpagelabels=false} !
% \documentclass[final,hyperref={pdfpagelabels=false}]{beamer} 
% beamer 3.07: get rid of beamer warnings

\mode<presentation> {  
%% check http://www-i6.informatik.rwth-aachen.de/~dreuw/latexbeamerposter.php for examples
  \usetheme{Durham} %% This points to the theme cooked up by the final year tutor
}
% \usepackage{beamerthemeDurham}
% \usepackage{titlesec}
\usepackage[english]{babel} 
% \usepackage{durhamtheme}
\usepackage[latin1]{inputenc}
\usepackage{amsmath,amsthm, amssymb, latexsym}
  \usefonttheme[onlymath]{serif}
  \boldmath
  \usepackage[orientation=portrait,size=a2,scale=1.25,debug]{beamerposter}                       
  \usepackage{wrapfig}
  % e.g. for DIN-A0 poster
  % \usepackage[orientation=portrait,size=a1,scale=1.4,grid,debug]{beamerposter}
  % e.g. for DIN-A1 poster, with optional grid and debug output
  % \usepackage[size=custom,width=200,height=120,scale=2,debug]{beamerposter} % e.g. for custom size poster
  % \usepackage[orientation=portrait,size=a0,scale=1.0,printer=rwth-glossy-uv.df]{beamerposter}
  % e.g. for DIN-A0 poster with rwth-glossy-uv printer check ...
  %

  \title[Final Year Project Poster]{Facial Liveness Testing For The Web}
  \author[R Collins]{Ryan Collins}
  \institute[Durham]{Department of Computer Science, Durham University}
  \date{\today}

  \begin{document}
  \begin{frame}{} 

  \vfill
    \begin{columns}[t]
      \begin{column}{.48\linewidth}
        \begin{block}{What are Facial Liveness Tests?}
          Facial liveness tests are methods of detecting whether the person in front of the camera is, in fact, a real person. 
          Common methods of fooling existing recognition systems include displaying a printed piece of paper to a camera. Alternative methods involving high-resolution screens, or video playback are highly successful variants of these spoofing methods.
          As the facial liveness testing field becomes more innovative and better and detecting liveness, facial recognition systems can become more secure.  
          While spoofing attacks might appear realistic, there are numerous methods of detecting them. On a single image, one can consider the image quality, as spoofing attacks will contain fewer high frequencies. Furthermore, texture differences and facial structure differences can also be detected. With videos, movement between frames can be used to determine the depth or analyze movement.
          
          Differences between a spoofing attack (using the paper-based attack method), and a real input, can be seen in the images below.

          To the untrained eye, the below example is obvious. However, in cases which only show the face, this classification can become much more difficult. 

          \begin{figure}[!tbp]
            \centering
            \begin{minipage}[b]{0.3\textwidth}
              \centering
              \includegraphics[width=100px]{RealImage.jpg}
              \caption{A real image of a person. Image from the NUAA dataset.}
            \end{minipage}
            \begin{minipage}[b]{0.3\textwidth}
              \centering
              \includegraphics[width=100px]{SpoofedImage.jpg}
            \caption{A spoofed image with a paper based replay attack. Image from the NUAA dataset.}
            \end{minipage}
          \end{figure}
        
        \end{block}
        \begin{block}{Why is my work important?}
          Facial recognition systems are only as good as the liveness systems that they employ. Better liveness systems lead to more secure facial recognition systems. Throughout this project, the aim was to develop liveness tests that can work with standard hardware available and allow use in real time. By doing this, future recognition systems will become more secure, while also not being too burdensome on the users. 
        \end{block}
        \begin{block}{Consolidation Layer - A method to fuse liveness test results together}
          Using a similar approach as the Image Quality Assessment method, bringing together the results of several liveness tests could yield
          better results. As such, analysis was undertaken on the results of the two liveness metrics produced.

          It was found that the liveness test results yielded a linearly separable pattern. This means that on a graph of one liveness test against another,
          a single line can be used to divide the two. While the entire dataset isn't fully linearly separable, there is a component. However, since this only works for 2 tests, it was decided to use
          Linear Discriminant Analysis to provide our liveness test fusion functionality.

          The result yielded reasonable results, gaining 75\% accuracy over the Replay-Attack test dataset, although more work is still necessary to determine the benefits gained over different datasets and a larger variety of liveness tests,
          since two isn't enough.
        \end{block}

        \begin{block}{Method 1: CNN based liveness detector}
          \begin{wrapfigure}{l}{100px}
            \includegraphics[width=100px]{2DCNNArchitecture.pdf}
          \end{wrapfigure}
          % TODO redo this making it more left-right compared to down. This way it'll fit properly and wrap ideally.
          Recently, Convolutional Neural Networks have played a major part in image classification. Residual Networks have performed very well on the ImageNet dataset, classifying types of objects based on a 2D image. Since liveness detection is an image classification problem, this can be adapted to predict spoofing, specifically within a facial region.
     
          The facial area was obtained using a pre-trained CNN, which returned a bounding box containing the face. The 224x224 size image obtained was used to classify the liveness.

          Training a 50 layer ResNet would take a very long time, and therefore a pre-trained model was used to improve results and reduce training time. The first 49 layers were left frozen, while the last layer was allowed to be modified. Attached to the ResNet 50 model was a feed-forward neural network, used to obtain a metric of 'realness': how real the subject in the image is.


          \begin{figure}
            \centering
            \includegraphics[width=100px]{FaceExtraction.png}
            \caption{The result of the preprocessing step, yielding a cropped face.}
          \end{figure}

          Accuracy yielded was adequate, with a 71\% accuracy on the Replay Attack test dataset. 
          However, the model had a very low false positive rate,
          with most errors being caused by false negatives (which is annoying for a user but not a security threat).

        \end{block}
      \end{column}

      \begin{column}{.48\linewidth}
        \begin{block}{Method 2: Whole Image Quality Assessment}
          \begin{wrapfigure}{r}{200px}
            \includegraphics[width=200px]{ImageQualityLivenessTest.pdf}
          \end{wrapfigure}
          This method considers the whole image quality, as a spoofed image is likely to have less details than a non-spoofed image.
          This liveness test uses 24 different methods of measuring image quality. Some metrics are full reference, which require the use of a Gaussian Blurred
          version of the image to compare to, which analyze the overall pixel based error, image noise, and frequency ranges. Other quality metrics use pretrained classifiers
          to analyze quality.
        
          The results of these quality metrics are then fed through a classifier. The classifier used was Linear Discriminant Analysis, with an eigenvector solver.
          Below, a diagram of how this system works can be seen.

          Overall, this method led to 87\% accuracy when classifying liveness on the Replay-Attack test dataset. 
          A high number of true negatives and positives were yielded, but when an error occurred, the classifier was more likely to class
          spoofed images as real, compared to the other way around, which isn't ideal for security conscious applications.

          The current method does have drawbacks, as the training data led to an expected resolution, and with images of different resolutions
          the prediction is often erroneous. One solution is to include resolution as it's own image quality metric within the classifier. For the demo,
          the solution was to resize an input image down to (640x480), which solves the problem temporarily, but future improvements should be able to predict
          liveness without this resize step.

          Furthermore, while the time to predict a single image is fairly fast, it could be improved further by migrating to a sklearn based classifier for the BIQI image quality metric.
          Currently, a libsvm based classifier is used, which is called by accessing the file system. This is very slow.

        \end{block}
        \begin{block}{Method 3: 2D reconstruction Mask Attack Detection Liveness Test}
          This used a pretrained 2D to 3D reconstruction model to produce a 3D model of a face. This 3D model was then fed through a VoxNet based
          classifier using several convolutional layers with a large number of filters. While an interesting idea, this method required far too much time
          to reconstruct a face, and required very large amounts of memory to predict. Therefore, training was impossible with the resources available. As such, this model wasn't suitable for
          a real time approach. 
        \end{block}
        % \begin{block}{What about Mask Attacks?}
        %   3D based mask attacks were also considered, where a spoofer is wearing the mask of a victim. This was deemed harder to detect, due to the requirement of 3D data.
        %   As a result, a new 3D based liveness test was designed. This model used an existing model to reconstruct a face from 2D into a 3D based voxel structure.

        %   Once this 3D reconstruction was obtained, the idea was to classify liveness based on this 3D structure, using a 3D convolutional network called VoxNet. While the idea was sound, in practice this didn't work out
        %   due to the 5 second time requirement to reconstruct a 2D face image in 3D, coupled with the very high memory requirements of the model for training and prediction purposes. A model that yielded an accuracy above 50\% (which is the same as random predictions),
        %   could not be obtained, since a model containing enough filters and dimensions could not be trained due to memory constrains. As a result, this model was deemed not to be feasible
        %   for a real-time prediction system.
          
        %   In future, a ResNet50 based 2D classifier could be tried to determine whether mask attacks could be detected from a 2D image.
        % \end{block}
     


        \begin{block}{Real-time Liveness System - a proof of concept}
          The liveness methods above were brought together into a real-time liveness detection system, utilizing an OpenCV based GUI.
          While simple, this could be further improved in the future to allow for liveness as a service platform, allowing developers to calculate liveness on the cloud,
          rather than relying on built-in features. For the screenshots below, videos from the Replay-Attack dataset were used, but this system also allows for webcam access in real time.
          This is a proof of concept of a future liveness system that could be put into production.

          \begin{figure}[!tbp]
            \centering
            \begin{minipage}[b]{0.3\textwidth}
              \centering
              \includegraphics[width=100px]{FakeOutputAndCorrect.png}
              \caption{A spoofed image being correctly classified as fake by both liveness tests. Frames obtained from the Replay-Attack test dataset.}
            \end{minipage}
            \begin{minipage}[b]{0.3\textwidth}
              \centering
              \includegraphics[width=100px]{BothRealAndCorrect.png}
            \caption{A real image being correctly classified as real. Frames obtained from the Replay-Attack test dataset.}
            \end{minipage}
          \end{figure}
          
          One additional finding by testing in real time was that the CNN based liveness test was often correct in it's prediction, but occasionally would
          switch to a prediction of 'fake' for a single frame. Therefore, the liveness test could be improved by analyzing several frames, and determine the modal liveness from that set of frames.
          
          Furthermore, and improvement that can be made to this is to speed the calculation of each liveness test up a bit. Currently, each liveness test is called and executed individually, in series. This could be parallelised,
          either on one machine or by using distributed computing technologies.
        \end{block}
        
      \end{column}
    \end{columns}

  % \vfill
  %   \begin{block}{\large This shows different font sizes you can use}
  %     \centering
  %     {\tiny tiny}\par
  %     {\scriptsize scriptsize}\par
  %     {\footnotesize footnotesize}\par
  %     {\normalsize normalsize}\par
  %     {\large large}\par
  %     {\Large Large}\par
  %     {\LARGE LARGE}\par
  %     {\veryHuge VeryHuge}\par
  %     {\VeryHuge VeryHuge}\par
  %     {\VERYHuge VERYHuge}\par
  %   \end{block}
  %   \vfill

  \end{frame}
\end{document}
